{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,subprocess\n",
    "workdir='/mnt/Data1/ribli/expression_code/modelling/'\n",
    "subprocess.call(['mkdir',workdir])\n",
    "os.chdir(workdir)\n",
    "\n",
    "#theano gpu\n",
    "os.environ['THEANO_FLAGS']='device=gpu'\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('../my_modules')\n",
    "#from loading_utils import read_my_data\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def read_my_data(fname,**kwargs):\n",
    "    \"\"\"Load my data from file into np.arrays.\n",
    "    \n",
    "    I had to use garbage collector, because pandas read_csv leaves garbage around.\n",
    "    \"\"\"\n",
    "    \n",
    "    #load data\n",
    "    print \"Loading data... \"\n",
    "    x=pd.read_csv(fname,sep='\\t',header=None)\n",
    "    \n",
    "    # for some reason not everything is cleaned up\n",
    "    #when using the pandas read_csv\n",
    "    gc.collect()\n",
    "    \n",
    "    #probe_id=x[0]\n",
    "    #y=x.iloc[:,-1].values.astype(np.int8)\n",
    "    #x=x.iloc[:,1:-1].values.astype(np.int8)\n",
    "    #return probe_id,x,y\n",
    "    \n",
    "    return x[0],x.iloc[:,1:-1].values.astype(np.int8),x.iloc[:,-1].values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "(234025, 800)\n"
     ]
    }
   ],
   "source": [
    "train_id,train_x,train_y = read_my_data(fname='../prepare_data/naive_feat_vect.csv')\n",
    "print train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234025, 1, 800, 4)\n"
     ]
    }
   ],
   "source": [
    "#make it image like\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "train_x=lb.fit_transform(np.concatenate([train_x.flatten()])).reshape((-1,1,800,4))\n",
    "print train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y=(0.5*(np.sign(train_y-np.median(train_y))+1)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 670 (CNMeM is disabled, CuDNN not available)\n",
      "/mnt/Data1/ribli/tools/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "\n",
    "input_dim=train_x.shape[2]\n",
    "activation='relu'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='adadelta'\n",
    "init='uniform'\n",
    "pool_size=(8,1)\n",
    "window_size=10\n",
    "dense_n=64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "model.add(Convolution2D(40,window_size,4, border_mode='valid',input_shape=(1,input_dim,4)))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "#Convolution layer 2\n",
    "model.add(Convolution2D(50,window_size,1, border_mode='valid'))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_n,activation=activation))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=loss,optimizer=optimizer,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "def fit_keras_model(model,train_x,train_y,test_x,test_y,validation_split=0.05):\n",
    "    start=time.time()\n",
    "    \n",
    "    #callbacks\n",
    "    best_model=ModelCheckpoint('best_model',save_best_only=True,verbose=1)\n",
    "    early_stop=EarlyStopping(patience=7,verbose=1)\n",
    "    \n",
    "    #train it\n",
    "    callb_hist=model.fit(train_x,train_y,nb_epoch = 100,\n",
    "                         show_accuracy=True,verbose=1,\n",
    "                        validation_split=validation_split,\n",
    "                        callbacks=[best_model,early_stop])\n",
    "    #predict\n",
    "    model.load_weights('best_model')\n",
    "    train_pred=model.predict_classes(train_x).ravel()\n",
    "    test_pred=model.predict_classes(test_x).ravel()\n",
    "    \n",
    "    train_pred_pr=model.predict(train_x).ravel()\n",
    "    test_pred_pr=model.predict(test_x).ravel()\n",
    "\n",
    "    #check errors\n",
    "    print 'train accuracy:',list((train_pred==train_y)).count(True)/float(len(train_y))\n",
    "    print 'test accuracy:',list((test_pred==test_y)).count(True)/float(len(test_y))\n",
    "\n",
    "    print 'It took:',time.time()-start    \n",
    "    return train_pred,test_pred,train_pred_pr,test_pred_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 152000 samples, validate on 38000 samples\n",
      "Epoch 1/100\n",
      " 11264/152000 [=>............................] - ETA: 84s - loss: 0.7195 - acc: 0.5028"
     ]
    }
   ],
   "source": [
    "N_train=190000\n",
    "N_test=40000\n",
    "\n",
    "train_pred,test_pred,train_pred_pr,test_pred_pr=fit_keras_model(\n",
    "    model,train_x[:N_train],train_y[:N_train],\n",
    "    train_x[N_train:N_train+N_test],train_y[N_train:N_train+N_test],\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "def plot_roc(y,probs):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y,probs)\n",
    "    auc=metrics.roc_auc_score(y,probs)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr,tpr,lw=2)\n",
    "    plt.plot([0,1],[0,1],lw=2)\n",
    "    plt.xlim(-0.01,1.01)\n",
    "    plt.ylim(-0.01,1.01)\n",
    "    plt.xlabel('FP rate')\n",
    "    plt.ylabel('TP rate')\n",
    "    print 'auc:',auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc(train_y[N_train:N_train+N_test],test_pred_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1=model.layers[0]\n",
    "weigths,bias=conv1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w, in weigths:\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.imshow(w.T,interpolation='none',aspect=0.5,cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    dump=plt.yticks([0,1,2,3],['A','C','G','T'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
